From 004592dcbd497b4852750aca0139d3ae12233abb Mon Sep 17 00:00:00 2001
From: Max Ihlenfeldt <max@igalia.com>
Date: Mon, 7 Aug 2023 10:37:59 +0000
Subject: [PATCH] Revert "Reland "Reland "mte: refactor the tagging functions
 to use ifuncs"""

This reverts https://crrev.com/c/4517702. The code compiles fine with
clang 15 (if you backport https://crrev.com/c/4610745), but clang 14
seems to contain a bug that leads to this build error:

```
IFunc resolver has incorrect type
i8* (i8*, i64)* @_ZN15partition_alloc8internal31TagMemoryRangeIncrementInternalEPvm
IFunc resolver has incorrect type
i8* (i8*, i64, i64)* @_ZN15partition_alloc8internal30TagMemoryRangeRandomlyInternalEPvmm
IFunc resolver has incorrect type
i8* (i8*)* @_ZN15partition_alloc8internal21RemaskPointerInternalEPv
LLVM ERROR: Broken module found, compilation aborted!
PLEASE submit a bug report to https://github.com/llvm/llvm-project/issues/ and include the crash backtrace.
```

Upstream-Status: Inappropriate [specific to older versions of clang]
Signed-off-by: Max Ihlenfeldt <max@igalia.com>
---
 .../partition_allocator/partition_root.cc     |  4 ++
 base/allocator/partition_allocator/tagging.cc | 56 ++++++-------------
 base/allocator/partition_allocator/tagging.h  | 43 +++++++++-----
 .../partition_allocator/tagging_unittest.cc   |  8 +++
 4 files changed, 60 insertions(+), 51 deletions(-)

diff --git a/base/allocator/partition_allocator/partition_root.cc b/base/allocator/partition_allocator/partition_root.cc
index dd78098..c47b8ba 100644
--- a/base/allocator/partition_allocator/partition_root.cc
+++ b/base/allocator/partition_allocator/partition_root.cc
@@ -864,6 +864,10 @@ void PartitionRoot::Init(PartitionOptions opts) {
       return;
     }

+    // Swaps out the active no-op tagging intrinsics with MTE-capable ones, if
+    // running on the right hardware.
+    ::partition_alloc::internal::InitializeMTESupportIfNeeded();
+
 #if BUILDFLAG(HAS_64_BIT_POINTERS)
     // Reserve address space for partition alloc.
     internal::PartitionAddressSpace::Init();
diff --git a/base/allocator/partition_allocator/tagging.cc b/base/allocator/partition_allocator/tagging.cc
index a1584dc..c3751ea 100644
--- a/base/allocator/partition_allocator/tagging.cc
+++ b/base/allocator/partition_allocator/tagging.cc
@@ -12,9 +12,7 @@

 #if PA_CONFIG(HAS_MEMORY_TAGGING)
 #include <arm_acle.h>
-#include <asm/hwcap.h>
 #include <sys/auxv.h>
-#include <sys/ifunc.h>
 #include <sys/prctl.h>
 #define PR_SET_TAGGED_ADDR_CTRL 55
 #define PR_GET_TAGGED_ADDR_CTRL 56
@@ -122,6 +120,12 @@ namespace {
   return ret;
 }

+#if PA_CONFIG(HAS_MEMORY_TAGGING)
+static bool HasCPUMemoryTaggingExtension() {
+  return base::CPU::GetInstanceNoAllocation().has_mte();
+}
+#endif  // PA_CONFIG(HAS_MEMORY_TAGGING)
+
 #if PA_CONFIG(HAS_MEMORY_TAGGING)
 void* TagRegionRandomlyForMTE(void* ptr, size_t sz, uint64_t mask) {
   // Randomly tag a region (MTE-enabled systems only). The first 16-byte
@@ -163,6 +167,7 @@ void* RemaskVoidPtrForMTE(void* ptr) {
   }
   return nullptr;
 }
+#endif

 void* TagRegionIncrementNoOp(void* ptr, size_t sz) {
   // Region parameters are checked even on non-MTE systems to check the
@@ -179,49 +184,24 @@ void* TagRegionRandomlyNoOp(void* ptr, size_t sz, uint64_t mask) {
 void* RemaskVoidPtrNoOp(void* ptr) {
   return ptr;
 }
-#endif

 }  // namespace

+void InitializeMTESupportIfNeeded() {
 #if PA_CONFIG(HAS_MEMORY_TAGGING)
-using RemaskPtrInternalFn = void*(void* ptr);
-using TagMemoryRangeIncrementInternalFn = void*(void* ptr, size_t size);
-
-using TagMemoryRangeRandomlyInternalFn = void*(void* ptr,
-                                               size_t size,
-                                               uint64_t mask);
-
-extern "C" TagMemoryRangeIncrementInternalFn(
-    *ResolveTagMemoryRangeIncrement(uint64_t hwcap, struct __ifunc_arg_t* hw)) {
-  if ((hwcap & _IFUNC_ARG_HWCAP) && (hw->_hwcap2 & HWCAP2_MTE)) {
-    return TagRegionIncrementForMTE;
+  if (HasCPUMemoryTaggingExtension()) {
+    global_remask_void_ptr_fn = RemaskVoidPtrForMTE;
+    global_tag_memory_range_increment_fn = TagRegionIncrementForMTE;
+    global_tag_memory_range_randomly_fn = TagRegionRandomlyForMTE;
   }
-  return TagRegionIncrementNoOp;
-}
-
-extern "C" TagMemoryRangeRandomlyInternalFn(
-    *ResolveTagMemoryRandomly(uint64_t hwcap, struct __ifunc_arg_t* hw)) {
-  if ((hwcap & _IFUNC_ARG_HWCAP) && (hw->_hwcap2 & HWCAP2_MTE)) {
-    return TagRegionRandomlyForMTE;
-  }
-  return TagRegionRandomlyNoOp;
-}
-
-extern "C" RemaskPtrInternalFn(
-    *ResolveRemaskPointer(uint64_t hwcap, struct __ifunc_arg_t* hw)) {
-  if ((hwcap & _IFUNC_ARG_HWCAP) && (hw->_hwcap2 & HWCAP2_MTE)) {
-    return RemaskVoidPtrForMTE;
-  }
-  return RemaskVoidPtrNoOp;
+#endif
 }

-void* TagMemoryRangeIncrementInternal(void* ptr, size_t size)
-    __attribute__((ifunc("ResolveTagMemoryRangeIncrement")));
-void* TagMemoryRangeRandomlyInternal(void* ptr, size_t size, uint64_t mask)
-    __attribute__((ifunc("ResolveTagMemoryRandomly")));
-void* RemaskPointerInternal(void* ptr)
-    __attribute__((ifunc("ResolveRemaskPointer")));
-#endif // PA_CONFIG(HAS_MEMORY_TAGGING)
+RemaskPtrInternalFn* global_remask_void_ptr_fn = RemaskVoidPtrNoOp;
+TagMemoryRangeIncrementInternalFn* global_tag_memory_range_increment_fn =
+    TagRegionIncrementNoOp;
+TagMemoryRangeRandomlyInternalFn* global_tag_memory_range_randomly_fn =
+    TagRegionRandomlyNoOp;

 TagViolationReportingMode GetMemoryTaggingModeForCurrentThread() {
 #if PA_CONFIG(HAS_MEMORY_TAGGING)
diff --git a/base/allocator/partition_allocator/tagging.h b/base/allocator/partition_allocator/tagging.h
index 1efbda2..f37ff1c 100644
--- a/base/allocator/partition_allocator/tagging.h
+++ b/base/allocator/partition_allocator/tagging.h
@@ -56,23 +56,39 @@ void ChangeMemoryTaggingModeForAllThreadsPerProcess(TagViolationReportingMode);
 PA_COMPONENT_EXPORT(PARTITION_ALLOC)
 TagViolationReportingMode GetMemoryTaggingModeForCurrentThread();

-// These forward-defined functions do not really exist in tagging.cc, they're
-// resolved by the dynamic linker to MTE-capable versions on the right hardware.
-#if PA_CONFIG(HAS_MEMORY_TAGGING)
-PA_COMPONENT_EXPORT(PARTITION_ALLOC)
-void* TagMemoryRangeIncrementInternal(void* ptr, size_t size);
-PA_COMPONENT_EXPORT(PARTITION_ALLOC)
-void* TagMemoryRangeRandomlyInternal(void* ptr, size_t size, uint64_t mask);
-PA_COMPONENT_EXPORT(PARTITION_ALLOC)
-void* RemaskPointerInternal(void* ptr);
-#endif
+// Called by the partition allocator after initial startup, this detects MTE
+// support in the current CPU and replaces the active tagging intrinsics with
+// MTE versions if needed.
+PA_COMPONENT_EXPORT(PARTITION_ALLOC) void InitializeMTESupportIfNeeded();
+
+// These global function pointers hold the implementations of the tagging
+// intrinsics (TagMemoryRangeRandomly, TagMemoryRangeIncrement, RemaskPtr).
+// They are designed to be callable without taking a branch. They are initially
+// set to no-op functions in tagging.cc, but can be replaced with MTE-capable
+// ones through InitializeMTEIfNeeded(). This is conceptually similar to an
+// IFUNC, even though less secure. These function pointers were introduced to
+// support older Android releases. With the removal of support for Android M,
+// it became possible to use IFUNC instead.
+// TODO(bartekn): void* -> uintptr_t
+using RemaskPtrInternalFn = void*(void* ptr);
+using TagMemoryRangeIncrementInternalFn = void*(void* ptr, size_t size);
+
+using TagMemoryRangeRandomlyInternalFn = void*(void* ptr,
+                                               size_t size,
+                                               uint64_t mask);
+extern PA_COMPONENT_EXPORT(PARTITION_ALLOC)
+    TagMemoryRangeRandomlyInternalFn* global_tag_memory_range_randomly_fn;
+extern PA_COMPONENT_EXPORT(PARTITION_ALLOC)
+    TagMemoryRangeIncrementInternalFn* global_tag_memory_range_increment_fn;
+extern PA_COMPONENT_EXPORT(PARTITION_ALLOC)
+    RemaskPtrInternalFn* global_remask_void_ptr_fn;

 // Increments the tag of the memory range ptr. Useful for provable revocations
 // (e.g. free). Returns the pointer with the new tag. Ensures that the entire
 // range is set to the same tag.
 PA_ALWAYS_INLINE void* TagMemoryRangeIncrement(void* ptr, size_t size) {
 #if PA_CONFIG(HAS_MEMORY_TAGGING)
-  return TagMemoryRangeIncrementInternal(ptr, size);
+  return global_tag_memory_range_increment_fn(ptr, size);
 #else
   return ptr;
 #endif
@@ -91,7 +107,7 @@ PA_ALWAYS_INLINE void* TagMemoryRangeRandomly(uintptr_t address,
   void* ptr = reinterpret_cast<void*>(address);
 #if PA_CONFIG(HAS_MEMORY_TAGGING)
   return reinterpret_cast<void*>(
-      TagMemoryRangeRandomlyInternal(ptr, size, mask));
+      global_tag_memory_range_randomly_fn(ptr, size, mask));
 #else
   return ptr;
 #endif
@@ -101,7 +117,7 @@ PA_ALWAYS_INLINE void* TagMemoryRangeRandomly(uintptr_t address,
 template <typename T>
 PA_ALWAYS_INLINE T* TagPtr(T* ptr) {
 #if PA_CONFIG(HAS_MEMORY_TAGGING)
-  return reinterpret_cast<T*>(RemaskPointerInternal(ptr));
+  return reinterpret_cast<T*>(global_remask_void_ptr_fn(ptr));
 #else
   return ptr;
 #endif
diff --git a/base/allocator/partition_allocator/tagging_unittest.cc b/base/allocator/partition_allocator/tagging_unittest.cc
index 5c25a46..fab5db7 100644
--- a/base/allocator/partition_allocator/tagging_unittest.cc
+++ b/base/allocator/partition_allocator/tagging_unittest.cc
@@ -16,6 +16,7 @@ namespace partition_alloc::internal {

 // Check whether we can call the tagging intrinsics safely on all architectures.
 TEST(PartitionAllocMemoryTaggingTest, TagMemoryRangeRandomlySafe) {
+  ::partition_alloc::internal::InitializeMTESupportIfNeeded();
   uintptr_t buffer =
       AllocPages(PageAllocationGranularity(), PageAllocationGranularity(),
                  PageAccessibilityConfiguration(
@@ -31,6 +32,7 @@ TEST(PartitionAllocMemoryTaggingTest, TagMemoryRangeRandomlySafe) {
 }

 TEST(PartitionAllocMemoryTaggingTest, TagMemoryRangeIncrementSafe) {
+  ::partition_alloc::internal::InitializeMTESupportIfNeeded();
   base::CPU cpu;
   uintptr_t buffer =
       AllocPages(PageAllocationGranularity(), PageAllocationGranularity(),
@@ -52,6 +54,7 @@ TEST(PartitionAllocMemoryTaggingTest, TagMemoryRangeIncrementSafe) {
 #if defined(ARCH_CPU_64_BITS)
 // Size / alignment constraints are only enforced on 64-bit architectures.
 TEST(PartitionAllocMemoryTaggingTest, TagMemoryRangeBadSz) {
+  ::partition_alloc::internal::InitializeMTESupportIfNeeded();
   base::CPU cpu;
   uintptr_t buffer =
       AllocPages(PageAllocationGranularity(), PageAllocationGranularity(),
@@ -68,6 +71,7 @@ TEST(PartitionAllocMemoryTaggingTest, TagMemoryRangeBadSz) {
 }

 TEST(PartitionAllocMemoryTaggingTest, TagMemoryRangeRandomlyNoSz) {
+  ::partition_alloc::internal::InitializeMTESupportIfNeeded();
   base::CPU cpu;
   uintptr_t buffer =
       AllocPages(PageAllocationGranularity(), PageAllocationGranularity(),
@@ -83,6 +87,7 @@ TEST(PartitionAllocMemoryTaggingTest, TagMemoryRangeRandomlyNoSz) {
 }

 TEST(PartitionAllocMemoryTaggingTest, TagMemoryRangeRandomlyBadAlign) {
+  ::partition_alloc::internal::InitializeMTESupportIfNeeded();
   base::CPU cpu;
   uintptr_t buffer =
       AllocPages(PageAllocationGranularity(), PageAllocationGranularity(),
@@ -99,6 +104,7 @@ TEST(PartitionAllocMemoryTaggingTest, TagMemoryRangeRandomlyBadAlign) {
 }

 TEST(PartitionAllocMemoryTaggingTest, TagMemoryRangeIncrementBadSz) {
+  ::partition_alloc::internal::InitializeMTESupportIfNeeded();
   base::CPU cpu;
   uintptr_t buffer =
       AllocPages(PageAllocationGranularity(), PageAllocationGranularity(),
@@ -114,6 +120,7 @@ TEST(PartitionAllocMemoryTaggingTest, TagMemoryRangeIncrementBadSz) {
 }

 TEST(PartitionAllocMemoryTaggingTest, TagMemoryRangeIncrementNoSz) {
+  ::partition_alloc::internal::InitializeMTESupportIfNeeded();
   base::CPU cpu;
   uintptr_t buffer =
       AllocPages(PageAllocationGranularity(), PageAllocationGranularity(),
@@ -129,6 +136,7 @@ TEST(PartitionAllocMemoryTaggingTest, TagMemoryRangeIncrementNoSz) {
 }

 TEST(PartitionAllocMemoryTaggingTest, TagMemoryRangeIncrementBadAlign) {
+  ::partition_alloc::internal::InitializeMTESupportIfNeeded();
   base::CPU cpu;
   uintptr_t buffer =
       AllocPages(PageAllocationGranularity(), PageAllocationGranularity(),
